# -*- coding: utf-8 -*-
"""20191574.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r87XWEaCyjYwvKjhJtArxKi3VSzXs9uO

# Face Recognition
---
해당 파일을 작성하여 12월 15일 자정까지 제출하시오.
제출할 때 ***학번.ipynb*** 파일로 저장하여 제출하기기 바랍니다.

### Dataset Description:
- 그레이 스케일 face 이미지 17장 + Non-face 이미지 1장 총 18장으로 구성
- 각 이미지의 사이즈는 195 × 231

- Training image: 8장
    - subject01.normal, subject02.normal, subject03.normal, subject07.normal, subject10.normal, subject11.normal, subject14.normal and subject15.normal

- Test image: 18장
    - Dataset의 모든 이미지 (face 17장 + non-face 1장)

### 데이터셋 준비
- https://docs.google.com/uc?export=download&id=1sWf596Yy4GkBxPA9VEiETPXPU3eYfs3H
- 위 주소로 압축 파일 다운로드 후 압축 해제
"""

# 압축 해제된 폴더의 전체 데이터 업로드 (전체 이미지 선택 후 일괄 업로드)
from google.colab import files

uploaded = files.upload()

# 파이썬 라이브러리 import
from matplotlib import pyplot as plt
from matplotlib.image import imread
import numpy as np
import os

"""## Read Images"""

dataset_path = './'
dataset_dir  = os.listdir(dataset_path)
dataset_dir = [img for img in dataset_dir if img.endswith(".jpg")]
dataset_dir = sorted(dataset_dir)

width  = 195
height = 231

print('Train Images:')
train_image_names = ['subject01.normal.jpg', 'subject02.normal.jpg', 'subject03.normal.jpg', 'subject07.normal.jpg', 'subject10.normal.jpg', 'subject11.normal.jpg', 'subject14.normal.jpg', 'subject15.normal.jpg']
training_tensor   = np.ndarray(shape=(len(train_image_names), height*width), dtype=np.float64)
print('Training tensor shape : ', training_tensor.shape)

plt.figure(figsize=(10, 8))
for i in range(len(train_image_names)):
    img = plt.imread(dataset_path + train_image_names[i])
    training_tensor[i,:] = np.array(img, dtype='float64').flatten()
    plt.subplot(2,4,1+i)
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

print('Test Images:')
test_image_names = dataset_dir#[i for i in dataset_dir if i not in train_image_names]
testing_tensor   = np.ndarray(shape=(len(test_image_names), height*width), dtype=np.float64)
print('Testing tensor shape : ', testing_tensor.shape)

plt.figure(figsize=(10, 8))
for i in range(len(test_image_names)):
    img = imread(dataset_path + test_image_names[i])
    testing_tensor[i,:] = np.array(img, dtype='float64').flatten()
    plt.subplot(3,6,1+i)
    plt.title(test_image_names[i].split('.')[0][-2:]+test_image_names[i].split('.')[1])
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.subplots_adjust(right=1.2, top=1.2)
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Mean face"""

# 모든 training face에 대한 mean face 이미지 생성
# training_tensor의 shape : (8, 45045) -> (training 이미지 개수, 이미지 height * 이미지 width)

# mean_face를 생성하는 코드를 작성하시오.
# training 이미지들의 평균을 구하여 만든 이미지이며 아래 출력과 같음.
mean_face = np.zeros((1,height*width))

# 코드 작성
for i in range(len(train_image_names)):
    img = plt.imread(dataset_path + train_image_names[i])
    mean_face+=np.array(img, dtype='float64').flatten()

mean_face=mean_face/len(train_image_names)

# mean_face 출력
plt.imshow(mean_face.reshape(height, width), cmap='gray')
plt.axis('off')
plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Normalized face"""

normalized_training_tensor = np.ndarray(shape=(len(train_image_names), height*width))

# normalized_training_tensor를 생성하는 코드를 작성하시오.
# training_tensor에서 각 training 이미지와 mean_face 이미지의 차를 (np.subtract) 이용해 nomalized face 이미지 획득
# 각 training image에 대한 normalized 이미지를 구한 뒤 normalized_training_tensor에 저장

# training_tensor shape : (8, 45045)
# mean_face shape : (1, 45045)
# normalized_training_tensor shape : (8, 45045)
# normalized_training_tensor의 출력은 아래 Display normalized faces와 같음.

# 코드 작성
for i in range(len(train_image_names)):
  normalized_training_tensor[i] = np.subtract(training_tensor[i], mean_face)

"""### Display normalized faces"""

plt.figure(figsize=(10, 8))
for i in range(len(train_image_names)):
    img = normalized_training_tensor[i].reshape(height,width)
    plt.subplot(2,4,1+i)
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Covariance matrix"""

# Normalized face 이미지들의 Convariance matrix 구하기
# normalized_training_tensor의 Covariance matrix cov_matrix를 구하는 코드를 작성하시오.
# 결과는 아래와 같음.
#np.cov
#np.divide 
#위의 두개의 함수 사용 가능

# 코드 작성
cov_matrix = np.cov(normalized_training_tensor)/len(normalized_training_tensor)
print('Covariance matrix of X: \n%s' %cov_matrix)

# 위에서 구한 Covariance matrix를 이용해 Eigenvalue, Eigenvector 구하기
# cov_matrix를 이용하여 eigenvalues, eigenvectors를 구하는 코드를 작성하시오.
# 결과는 아래와 같음.
#np.linalg.eig 사용

# 코드 작성
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

print('Eigenvectors of Cov(X): \n%s' %eigenvectors)
print('\nEigenvalues of Cov(X): \n%s' %eigenvalues)

# Eigenvalue, Eigenvector 쌍을 가진 list eig_pairs를 생성하고 list를 내림차순으로 정렬하여
# list eigvalues_sort, eigvectors_sort를 생성하는 코드를 작성하시오.
eig_pairs = []
for i in range(0, 8):
    eig_pairs.append((eigenvalues[i], eigenvectors[:,i]))
 
eig_pairs.sort(key=lambda x:-x[0])

eigvalues_sort = []
eigvectors_sort = []
for i in range(0, 8):
    eigvalues_sort.append(eig_pairs[i][0])
    eigvectors_sort.append(eig_pairs[i][1])

"""## Find cumulative variance of each Principal component"""

# Eigenvalue를 이용해 각 성분의 분산의 누적 비율을 (var_comp_sum) 계산하는 코드를 작성하시오.
# 결과는 아래와 같음.

# 코드 작성
var_comp_sum = np.cumsum(eigvalues_sort)/sum(eigvalues_sort)

# 각 성분들에 분산의 누적 비율
print("Cumulative proportion of variance explained vector: \n%s" %var_comp_sum)

# x-axis for number of principal components kept
num_comp = range(1,len(eigvalues_sort)+1)
plt.title('Cum. Prop. Variance Explain and Components Kept')
plt.xlabel('Principal Components')
plt.ylabel('Cum. Prop. Variance Expalined')

plt.scatter(num_comp, var_comp_sum)
plt.show()

"""### Choose the necessary no.of principal components:"""

reduced_data = np.array(eigvectors_sort[:7]).transpose()
reduced_data.shape

# Eigen space를 형성하는 projected 데이터 생성
# proj_data를 구하는 코드를 작성하시오.
# projected data는 training_tensor와 reduced_data를 내적하여 구함.
# proj_data를 구한 결과는 Plot eigen faces에서 보여줌.

# 코드 작성
proj_data = np.dot(reduced_data.T,training_tensor)

"""## Plot eigen faces"""

plt.figure(figsize=(10, 8))
for i in range(proj_data.shape[0]):
    img = proj_data[i].reshape(height,width)
    plt.subplot(2,4,1+i)
    plt.imshow(img, cmap='jet')
    plt.axis('off')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Finding weights for each traning image"""

# normalized_training_tensor의 각 normalized face 이미지와 Eigen face 이미지를 내적 하여 
# 각 이미지에 대한 weghit w를 계산하는 코드를 작성하시오.
# 결과는 아래와 같음.

# 코드 작성
w = normalized_training_tensor.dot(proj_data.T)
w

"""## Now we recognize unknown face!"""

unknown_face        = plt.imread('./subject12.normal.jpg')
unknown_face_vector = np.array(unknown_face, dtype='float64').flatten()

plt.imshow(unknown_face, cmap='gray')
plt.axis('off')
plt.title('Unknown face')
plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Normalize unknown face"""

# 위의 normalize 방법을 이용하여 unknown face에 대한
# normalized face인 normalized_uface_vector를 구하시오.
# 결과는 아래와 같음.

# 코드 작성
normalized_uface_vector = np.zeros((1,height*width))
for i in range(0, 8):
    normalized_uface_vector = np.subtract(unknown_face_vector, mean_face)

plt.imshow(normalized_uface_vector.reshape(height, width), cmap='gray')
plt.axis('off')
plt.title('Normalized unknown face')
plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## Wieghts of unknown face

Projecting the normalized vector onto the eigenspace, to find out the weights:
"""

# proj_data : 위에서 구한 Training의 eigen face 이미지
# unknown face 이미지와 training eigen face 이미지를 내적해
# unknown 이미지의 weight w_unknown을 계산하는 코드를 작성하시오.
# 결과는 아래와 같음.

# 코드 작성
w_unknown = np.dot(unknown_face_vector, proj_data.T)
w_unknown

"""Finding the $min|W - W_{unknown}|$

"""

# training 이미지들의 weight와 unknown 이미지 weight 차이 'diff'를 계산하는 코드를 작성
# L1 norm값들을 가진 'norms'를 구하여 출력
# norms 중 최소값을 출력
# 결과는 아래와 같음.

# 코드 작성
diff  = w - w_unknown
norms = np.linalg.norm(diff, axis=1)
index = np.argmin(norms)
print(norms)
print(norms[index])

"""## Reconizing all test images"""

count        = 0
num_images   = 0
correct_pred = 0
def recogniser(img, train_image_names,proj_data,w):
    global count,highest_min,num_images,correct_pred
    unknown_face        = plt.imread('./'+img)
    num_images          += 1
    unknown_face_vector = np.array(unknown_face, dtype='float64').flatten()
    normalized_uface_vector = np.subtract(unknown_face_vector,mean_face)
    
    plt.subplot(9,4,1+count)
    plt.imshow(unknown_face, cmap='gray')
    plt.axis('off')
    plt.title('Input:'+'.'.join(img.split('.')[:2]))
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
    count+=1
    
    w_unknown = np.dot(normalized_uface_vector, proj_data.T)
    diff  = w - w_unknown
    norms = np.linalg.norm(diff, axis=1)
    index = np.argmin(norms)
    
    t1 = 100111536
    #t1 = 200535910.268 # working with 6 faces
    #t0 = 86528212
    t0 = 88831687
    #t0 = 143559033 # working with 6 faces
    
    if norms[index] < t1:
        plt.subplot(9,4,1+count)
        if norms[index] < t0: # It's a face
            if img.split('.')[0] == train_image_names[index].split('.')[0]:
                plt.title('Matched:'+'.'.join(train_image_names[index].split('.')[:2]), color='g')
                plt.imshow(imread('./'+train_image_names[index]), cmap='gray')
                plt.axis('off')
                
                correct_pred += 1
            else:
                plt.title('Matched:'+'.'.join(train_image_names[index].split('.')[:2]), color='r')
                plt.imshow(imread('./'+train_image_names[index]), cmap='gray')
                plt.axis('off')
        else:
            if img.split('.')[0] not in [i.split('.')[0] for i in train_image_names] and img.split('.')[0] != 'apple':
                plt.title('Unknown face!', color='g')
                correct_pred += 1
            else:
                plt.title('Unknown face!', color='r')
        plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
        plt.subplots_adjust(right=1.2, top=2.5)
    else:     
        plt.subplot(9,4,1+count)
        if len(img.split('.')) == 3:
            plt.title('Not a face!', color='r')
        else:
            plt.title('Not a face!', color='g')
            correct_pred += 1
        plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
    count+=1

fig = plt.figure(figsize=(15, 15))
for i in range(len(test_image_names)):
    recogniser(test_image_names[i], train_image_names,proj_data,w)

plt.show()

print('Correct predictions: {}/{} = {}%'.format(correct_pred, num_images, correct_pred/num_images*100.00))

"""## Normalized images"""

count        = 0
def recogniser(img, train_image_names,proj_data,w):
    global count
    unknown_face        = plt.imread('./'+img)
    unknown_face_vector = np.array(unknown_face, dtype='float64').flatten()
    normalized_uface_vector = np.subtract(unknown_face_vector,mean_face)
    
    plt.subplot(9,4,1+count)
    plt.imshow(unknown_face, cmap='gray')
    plt.axis('off')
    plt.title('Input:'+'.'.join(img.split('.')[:2]))
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
    count+=1
    
    plt.subplot(9,4,1+count)
    plt.imshow(normalized_uface_vector.reshape(height, width), cmap='gray')
    plt.axis('off')
    plt.title('Normalized Face')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
    plt.subplots_adjust(right=1.2, top=2.5)
    count+=1

fig = plt.figure(figsize=(15, 15))
for i in range(len(test_image_names)):
    recogniser(test_image_names[i], train_image_names,proj_data,w)

plt.show()

